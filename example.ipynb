{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity with Replicate Embedding Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how you can use embedding models on Replicate to power tasks like semantic search or clustering. We'll use one of Replicate's hosted versions of [MPNet](https://replicate.com/replicate/all-mpnet-base-v2/versions/f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb), which is a pre-trained language model developed by Microsoft ([paper](https://arxiv.org/abs/2004.09297)).\n",
    "\n",
    "You'll learn how to:\n",
    "\n",
    "* Use the Replicate API to obtain embeddings for documents\n",
    "* Setup a semantic similarity system using just `numpy` and Replicate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install `replicate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting replicate\n",
      "  Downloading replicate-0.8.1.tar.gz (22 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pydantic>1 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from replicate) (1.10.7)\n",
      "Requirement already satisfied: requests>2 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from replicate) (2.28.2)\n",
      "Requirement already satisfied: packaging in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from replicate) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from pydantic>1->replicate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests>2->replicate) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests>2->replicate) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests>2->replicate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/.pyenv/versions/3.8.16/lib/python3.8/site-packages (from requests>2->replicate) (1.26.15)\n",
      "Building wheels for collected packages: replicate\n",
      "  Building wheel for replicate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for replicate: filename=replicate-0.8.1-py3-none-any.whl size=21099 sha256=e64c5db250e0537cef80716207a530f874962fa53df59bda75fc219da3c25df6\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/86/e0/876cae2f7d3eabe6e3adabcab93b95d38f6d38843a7c311aeb\n",
      "Successfully built replicate\n",
      "Installing collected packages: replicate\n",
      "Successfully installed replicate-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.1 is available.\n",
      "You should consider upgrading via the '/root/.pyenv/versions/3.8.16/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install replicate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the packages we'll rely on throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import replicate\n",
    "import numpy as np\n",
    "import json\n",
    "from functools import lru_cache\n",
    "from typing import List\n",
    "import logging\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify our Replicate API token, which can be found in your Replicate Profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLICATE_API_TOKEN = input('Enter your Replicate API token here:')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['REPLICATE_API_TOKEN'] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating embeddings for documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we're using is a sentence-transformer based on MPNet. \n",
    "\n",
    "Sentence-transformers are a specialized type of embedding model that generates a single numerical representation (embedding) for an entire document, such as a sentence or a paragraph. These models first calculate embeddings for individual tokens (words or subwords) in the document. Then, they perform mean-pooling over the token embeddings to generate a final document-level embedding. This representation captures the overall meaning of the document. By comparing the embeddings of different documents, you can measure their semantic similarity, which is useful for tasks like text classification, clustering, and search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain an embedding for a document, you can call the Replicate API with an input that specifies a `text` parameter. \n",
    "\n",
    "Note, you also need to specify the `model_version`, which, for the model we've selected is: \"replicate/all-mpnet-base-v2:f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "embedding = replicate.run(\n",
    "  model_version=\"replicate/all-mpnet-base-v2:f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb\",\n",
    "  input={\"text\": \"Map this into semantic space.\"}\n",
    ")\n",
    "\n",
    "print(len(embedding))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a `list` containing a single `list` of floats, which constitute the embedding values of your input document.\n",
    "\n",
    "## Batch Encoding\n",
    "\n",
    "Often, when we need to obtain embeddings for a large number of documents, it's better to encode documents in batches. If computation is executed on a GPU, this allows us to exploit GPU acceleration for parallel processes. To obtain embeddings for a batch of documents, you can use the `text_batch` argument instead of the `text` argument. \n",
    "\n",
    "`text_batch` expects a JSON-formatted list of documents, like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our JSON-formatted list of documents:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"This is a list of documents\", \"that will be processed as a batch.\"]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = [\"This is a list of documents\", \"that will be processed as a batch.\"]\n",
    "text_batch = json.dumps(candidates)\n",
    "print(\"Here's our JSON-formatted list of documents:\")\n",
    "text_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to obtain embeddings, we just need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "candidate_embeddings = replicate.run(\n",
    "  model_version=\"replicate/all-mpnet-base-v2:f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb\",\n",
    "  input={\"text_batch\": text_batch}\n",
    ")\n",
    "print(len(candidate_embeddings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, a `list` is returned. However, it now is has a length of 2, because it contains embeddings for two documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Semantic Search PoC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build out a Semantic Search PoC, which we'll implement as a simple Python class. During instantiation, our class will accept a list of candidate documents and it will compute and store their embeddings. We'll also design the `__call__` method so that calling an instance of the class with a query document will run a semantic search process against our candidate documents.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SemanticSearch:\n",
    "\n",
    "    def __init__(self, model_version, candidates):\n",
    "        self.model_version = model_version\n",
    "        self.candidates = candidates\n",
    "        self.candidate_embeddings = self.encode_candidates(candidates)\n",
    "    \n",
    "    def encode_candidates(self, candidates: List[str]):\n",
    "        \"\"\"\n",
    "        This function encodes the candidate documents into a `np.array` of embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Encoding {len(docs)} docs...\")\n",
    "\n",
    "        text_batch = json.dumps(candidates)\n",
    "        \n",
    "        doc_embeddings = replicate.run(\n",
    "            self.model_version,\n",
    "            input={\"text_batch\": text_batch}\n",
    "        )\n",
    "        \n",
    "        doc_embeddings = np.array(doc_embeddings)\n",
    "\n",
    "        return doc_embeddings\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def encode_query(self, query):\n",
    "        \"\"\"\n",
    "        This method encodes the query into a `np.array` of embeddings. It also uses a lru cache to avoid\n",
    "        recomputing embeddings for identical queries. \n",
    "        \"\"\"\n",
    "        query_embedding = replicate.run(\n",
    "            self.model_version,\n",
    "            input={\"text\": query}\n",
    "        )\n",
    "\n",
    "        query_embedding = np.array(query_embedding[0])\n",
    "\n",
    "        return query_embedding\n",
    "\n",
    "    @staticmethod\n",
    "    def _cos_sim(query_embedding, candidate_embeddings):\n",
    "        \"\"\"\n",
    "        This function computes the cosine similarities between a query embedding and an array of candidate embeddings.\n",
    "        \"\"\"\n",
    "        cosine_similarities = np.dot(candidate_embeddings, query_embedding) / (np.linalg.norm(candidate_embeddings, axis=1) * np.linalg.norm(query_embedding))\n",
    "        return cosine_similarities\n",
    "\n",
    "    \n",
    "    def __call__(self, query, candidate_embeddings=None, candidates=None):\n",
    "        \"\"\"\n",
    "        This method encodes `query` into an embedding, \n",
    "        calculates the cosine similarities between the query embedding and `candidate_embeddings`, and\n",
    "        returns the index and text the document with the highest cosine similarity.\n",
    "        \"\"\"\n",
    "        if not candidate_embeddings:\n",
    "            candidate_embeddings = self.candidate_embeddings\n",
    "        if not candidates:\n",
    "            candidates = self.candidates \n",
    "\n",
    "        # Get input embedding\n",
    "        query_embedding = self.encode_query(query)\n",
    "\n",
    "        # Compute the cosine similarity between the input embedding and all embeddings\n",
    "        cosine_similarities = self._cos_sim(query_embedding, candidate_embeddings)\n",
    "        \n",
    "        # Get the index of the nearest neighbor\n",
    "        indx = np.argsort(cosine_similarities)[-1]\n",
    "\n",
    "        return {\"id\": indx,  \"score\": cosine_similarities[indx], \"text\": candidates[indx]}\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we're ready to test it out. For this exercise, I've just specified an assortment of 10 strings that we'll use as our candidate documents. We'll use them to instantiate our SemanticSearch instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 10 docs...\n"
     ]
    }
   ],
   "source": [
    "model_id =   \"replicate/all-mpnet-base-v2:f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb\"\n",
    "\n",
    "candidates = [\n",
    "    \"The sun is shining and the birds are singing.\",\n",
    "    \"Cats and dogs are popular pets.\",\n",
    "    \"The ocean is deep and full of mysteries.\",\n",
    "    \"I love eating pizza and drinking beer.\",\n",
    "    \"Education is important for personal growth.\",\n",
    "    \"The city skyline at night is beautiful.\",\n",
    "    \"Dogs are loyal and loving companions.\",\n",
    "    \"Music has the power to evoke emotions.\",\n",
    "    \"Traveling to new places broadens your perspective.\",\n",
    "    \"Rainy days are perfect for curling up with a good book.\"\n",
    "]\n",
    "\n",
    "search = SemanticSearch(model_id, candidates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we call our class instance with a query string, that following steps will be performed:\n",
    "\n",
    "1. The query string will be encoded into an embedding\n",
    "2. The query embedding will be compared against each candidate embedding via cosine similarity\n",
    "3. The index and text of the candidate embedding with the highest cosine similarity will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'score': 0.7579522779442195,\n",
       " 'text': 'Cats and dogs are popular pets.'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"What kinds of pets are popular?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4,\n",
       " 'score': 0.4409378015110852,\n",
       " 'text': 'Education is important for personal growth.'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"Do you have any information on self-improvement?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we just built a simple, but effective semantic search PoC. What's next?\n",
    "\n",
    "Well, while it's easy to build out a PoC, it can be a bit more difficult to ensure your users enjoy the best possible experience. And, unfortunately, there's no one-size-fits-all solution. However, here are some things to consider as you build out your system:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your model trained to do?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, it's crucial to understand what your model was trained to do. For example, the model we've selected for this tutorial was trained to predict sentence pairs (see [here](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#:~:text=seb.sbert.net-,Background,-The%20project%20aims) for more details). This is a _great_ way to develop a pre-trained model that can be used to calculate the semantic similarity between between two sentences.\n",
    "\n",
    "However, there are also some important implications to consider. For example, this model was not explicitly and exclusively trained to perform question answering. This means that you can meaningfully calculate semantic similarity for query strings that are not questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 6,\n",
       " 'score': 0.6339098054211136,\n",
       " 'text': 'Dogs are loyal and loving companions.'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"I love dogs.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another implication is that you may observe decreased accuracy if you're encoding long documents. This particular model was fine-tuned on _sentences_ and it may/or may not be able to encode multi-sentence documents with comparable fidelity. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring high-quality responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our PoC implementation simply returns the candidate document that received the highest similarity score. However, what happens if there simply isn't a good candidate document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 5,\n",
       " 'score': 0.1848880883273737,\n",
       " 'text': 'The city skyline at night is beautiful.'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"What is the tallest mountain in the world?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would probably be better if we allowed our search system to abstain if no suitable matches were identified. \n",
    "\n",
    "We can do implement a naive solution simply by adding a threshold to our scoring process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SemanticSearch:\n",
    "\n",
    "    def __init__(self, model_version, candidates):\n",
    "        self.model_version = model_version\n",
    "        self.candidates = candidates\n",
    "        self.candidate_embeddings = self.encode_candidates(candidates)\n",
    "    \n",
    "    def encode_candidates(self, candidates: List[str]):\n",
    "        \"\"\"\n",
    "        This function encodes the candidate documents into a `np.array` of embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Encoding {len(docs)} docs...\")\n",
    "\n",
    "        text_batch = json.dumps(candidates)\n",
    "        \n",
    "        doc_embeddings = replicate.run(\n",
    "            self.model_version,\n",
    "            input={\"text_batch\": text_batch}\n",
    "        )\n",
    "        \n",
    "        doc_embeddings = np.array(doc_embeddings)\n",
    "\n",
    "        return doc_embeddings\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def encode_query(self, query):\n",
    "        \"\"\"\n",
    "        This method encodes the query into a `np.array` of embeddings. It also uses a lru cache to avoid\n",
    "        recomputing embeddings for identical queries. \n",
    "        \"\"\"\n",
    "        query_embedding = replicate.run(\n",
    "            self.model_version,\n",
    "            input={\"text\": query}\n",
    "        )\n",
    "\n",
    "        query_embedding = np.array(query_embedding[0])\n",
    "\n",
    "        return query_embedding\n",
    "\n",
    "    @staticmethod\n",
    "    def _cos_sim(query_embedding, candidate_embeddings):\n",
    "        \"\"\"\n",
    "        This function computes the cosine similarities between a query embedding and an array of candidate embeddings.\n",
    "        \"\"\"\n",
    "        cosine_similarities = np.dot(candidate_embeddings, query_embedding) / (np.linalg.norm(candidate_embeddings, axis=1) * np.linalg.norm(query_embedding))\n",
    "        return cosine_similarities\n",
    "\n",
    "    \n",
    "    def __call__(self, query, candidate_embeddings=None, candidates=None, similarity_threshold=0.40):\n",
    "        \"\"\"\n",
    "        This method encodes `query` into an embedding, \n",
    "        calculates the cosine similarities between the query embedding and `candidate_embeddings`, and\n",
    "        returns the index and text the document with the highest cosine similarity.\n",
    "        \"\"\"\n",
    "        if not candidate_embeddings:\n",
    "            candidate_embeddings = self.candidate_embeddings\n",
    "        if not candidates:\n",
    "            candidates = self.candidates \n",
    "\n",
    "        # Get input embedding\n",
    "        query_embedding = self.encode_query(query)\n",
    "\n",
    "        # Compute the cosine similarity between the input embedding and all embeddings\n",
    "        cosine_similarities = self._cos_sim(query_embedding, candidate_embeddings)\n",
    "        \n",
    "        # Get the index of the nearest neighbor\n",
    "        indx = np.argsort(cosine_similarities)[-1]\n",
    "        \n",
    "        # Abstain if similarity is not high enough\n",
    "        if cosine_similarities[indx] < similarity_threshold:\n",
    "            result = None\n",
    "        else:\n",
    "            result = {\"id\": indx,  \"score\": cosine_similarities[indx], \"text\": candidates[indx]}\n",
    "\n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 10 docs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': None, 'score': None, 'text': None}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id =   \"replicate/all-mpnet-base-v2:f7565bcaa9b9ec3f3560e57421d85d7788d5402f5df305f599f8d5cda0a6d6bb\"\n",
    "\n",
    "candidates = [\n",
    "    \"The sun is shining and the birds are singing.\",\n",
    "    \"Cats and dogs are popular pets.\",\n",
    "    \"The ocean is deep and full of mysteries.\",\n",
    "    \"I love eating pizza and drinking beer.\",\n",
    "    \"Education is important for personal growth.\",\n",
    "    \"The city skyline at night is beautiful.\",\n",
    "    \"Dogs are loyal and loving companions.\",\n",
    "    \"Music has the power to evoke emotions.\",\n",
    "    \"Traveling to new places broadens your perspective.\",\n",
    "    \"Rainy days are perfect for curling up with a good book.\"\n",
    "]\n",
    "\n",
    "search = SemanticSearch(model_id, candidates)\n",
    "search(\"What is the tallest mountain in the world?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our search system returns "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
